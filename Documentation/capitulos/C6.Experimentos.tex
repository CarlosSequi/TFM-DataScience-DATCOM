\chapter[Capítulo 6. Experimentos]{Experimentos}

Tras el análisis introductorio al contexto en el que nos situamos para hacer conocer al lector las técnicas que hay detrás del problema que queremos resolver y después de exponer y analizar la propuesta de trabajo a la que nos enfrentamos, entramos de lleno en la exposición del marco de trabajo en el que nos situaremos con los algoritmos que vamos a manejar, así como la muestra de resultados obtenidos en cuanto a comparativas realizadas y, por último, su posterior análisis, con el fin de concretar el éxito o fracaso de la teoría expuesta en capítulos anteriores.

\section{Marco de trabajo}

En esta sección, tal como hemos comentado, situaremos el marco de trabajo de nuestro experimento, formado por los conjuntos de datos que trataremos para este, junto con las medidas de precisión y monotonía que usaremos con los algoritmos con el fin de poder ser comparados por igual.

\subsection{Conjuntos de datos}

Primeramente comentaremos los conjuntos de datos a tratar con el fin de entender a que se enfrentarán nuestros algoritmos. Antes que nada cabe destacar que los data sets que vamos a utilizar son estáticos, es decir, no son datos que nos llegan en flujo (que es uno de los aspectos que queremos tratar en este documento), por tanto a la hora de realizar los experimentos habremos de simular la entrada de datos por un flujo en lugar de leerlos de forma directa. Los datos han sido sacados de \cite{ref16}



\begin{table}[]
	\begin{tabular}{|l|l|l|l|l|l|l|}
		\hline
		Data set & Instancias & Atributos & Numéricos & Nominales & Clases & NMI   \\ \hline
		ERA      & 1000       & 4         & 4         & 0         & 9      & 0.016 \\ \hline
		ESL      & 488        & 4         & 4         & 0         & 9      & 0.004 \\ \hline
		LEV      & 1000       & 4         & 4         & 0         & 5      & 0.006 \\ \hline
		SWD      & 1000       & 10        & 10        & 0         & 4      & 0.009 \\ \hline
	\end{tabular}
	\caption{Conjuntos de datos a utilizar en el experimento}
\end{table}

\subsubsection{Descripción de los conjuntos de datos}

\begin{itemize}
	\item \textbf{ERA}: recopilación de datos tomados durante un experimento académico de toma de decisiones académicas con el objetivo de determinar las cualidades más importantes  de los candidatos para ciertos tipos de trabajo.
	\item \textbf{ESL}: perfiles de aplicantes para ciertos trabajos en la industria. Psicólogos expertos determinaron los valores de los atributos de los datos basándose en resultados de tests psicométricos y entrevistas realizadas a los candidatos.
	\item \textbf{LEV}: estos datos hacen referencia a ejemplos de evaluaciones anónimas de profesores realizadas al final de cursos MBA (Master of Business Administration). Antes de recibir las notas finales, se le pidió a los estudiantes que puntuaran a sus profesores en concordancia a cuatro atributos como las habilidades orales y la contribución a su conocimiento profesional o general. La salida es una evaluación total del rendimiento del profesor.
	\item \textbf{SWD}: este conjunto de datos contiene evaluaciones reales de trabajadores sociales cualificados midiendo el riesgo de un grupo de niños al permanecer en casa con sus familias. Esta evaluación de riesgos se presenta a menudo en cortes judiciales para ayudar a decidir que le interesa más a un niño presuntamente maltratado o descuidado.
\end{itemize}



\subsection{Medidas}

Primeramente abordaremos las medidas destinadas a valorar la precisión y, posteriormente, aquellas cuyo objetivo es medir la monotonicidad \cite{ref15}.

\subsubsection{Medidas de precisión}

Dentro de las medidas de precisión para clasificación podemos encontrarlas de dos tipos: para clasificación binaria y para clasificación multiclase.

\textbf{Clasificación binaria}

Previa exposición de algunos de las medidas de clasificación binaria necesitamos tener en cuenta algunos términos con el fin de poder entenderlas:
\begin{itemize}
	\item \textbf{True Positives (TP)}: cantidad de instancias con predicción positiva que están correctamente clasificadas.
	\item \textbf{False Positives (FP)}: cantidad de instancias con predicción positiva que no están correctamente clasificadas.
	\item \textbf{True Negative (TN)}: cantidad de instancias con predicción negativa que están correctamente clasificadas.
	\item \textbf{False Negative (FN)}: cantidad de instancias con predicción negativa que no están correctamente clasificadas.
\end{itemize}

Una vez conocemos esta terminología, vemos algunas de las medidas para clasificación binaria:

\begin{itemize}
	\item \textbf{Accuracy}: Representa la habilidad predictiva de acuerdo con la proporción de 
	los datos clasificados de forma correcta.
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.5\textwidth]{imagenes/f2} 
	\end{figure}

	\item \textbf{Error rate}: Caso opuesto al accuracy, evaluando la proporción de los datos
	evaluados clasificados de forma incorrecta.
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.5\textwidth]{imagenes/f3} 
	\end{figure}

	\item \textbf{Recall/sensitivity}: Medida de la proporción de TP que están correctamente clasificados.
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.3\textwidth]{imagenes/f4} 
	\end{figure}

	\item \textbf{Positive predictive value(PPV)/Precisión}: Proporción de las instancias del test que tienen una
	salida positiva y que además están bien clasificados.
	representa la probabilidad de que una prueba positiva 
	refleje la condición subyacente que se está probando.
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.3\textwidth]{imagenes/f5} 
	\end{figure}
\end{itemize}



\textbf{Clasificación multiclase}

Procedemos ahora a exponer algunas medidas de predicción aplicadas a los problemas de clasificación multiclase. Para ambas medidas hemos de tener en cuenta lo siguiente: n corresponde a la cantidad de observaciones en el conjunto de datos evaluados, $y'_i$ es la clase predicha para una instancia i e $y_i$ es la etiqueta de clase real (ambos representados como valores enteros basados en su posición en la escala ordinal).

\begin{itemize}
	\item \textbf{Mean Squared Error (MSE)}: Mide la media de los cuadrados de los errores. Al usar los cuadrados de $y_i$ e $y'_i$ se pondera con un peso mayor a los errores más grandes.
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.4\textwidth]{imagenes/f6} 
	\end{figure}

	\item \textbf{Mean Absolute Error (MAE)}: Mide cómo de cerca se encuentran las predicciones de los valores reales de salida. MAE es una medida lineal, lo que significa que los errores son tratados con el mismo peso en la media.
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.4\textwidth]{imagenes/f7} 
	\end{figure}
\end{itemize}

Dados los conjuntos de datos de los que disponemos y el uso que la literatura recomienda hacer de las medidas de precisión sobre este tipo de conjuntos de datos, utilizaremos la medida\textbf{ Mean Absolute Error (MAE)} para la evaluación de la precisión de nuestros algoritmos, ya que los conjuntos que manejaremos son de clasificación multiclase.

\subsubsection{Medidas de monotonicidad}

Nuestro propósito con esta medida es evaluar la tasa de monotonicidad provista tanto por las predicciones obtenidas y el conjunto de datos original, como de la construcción del modelo.

Para ello tenemos en cuenta las siguientes consideraciones:
\begin{itemize}
	\item x es un ejemplo del conjunto de datos D.
	\item NClash(x) es la cantidad de ejemplos de D que no cumplen las restricciones de monotonicidad con respecto a x.
	\item n es el número de instancias en D.
	\item NMonot(x) es el número de ejemplos de D que sí que cumplen las restricciones de monotonicidad con respecto a x.
\end{itemize}

El \textbf{Índice de no-monotonicidad} se define como el número de choques (Nclash) dividido por el número de pares de ejemplos en el conjunto de datos:

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\textwidth]{imagenes/f8} 
\end{figure}

Y esta será la medida que utilicemos finalmente para la evaluación de la monotonicidad en nuestros algoritmos.

\section{Resultados}

A continuación muestro las condiciones bajo las que se han ejecutado todas las tablas de resultados que mostraré a continuación. Estas condiciones son los parámetros de Hoeffding Tree ajustados para obtener un árboles lo suficientemente representativos de los datos.
\begin{itemize}
	\item Parámetro de desempate: 1
	\item Parámetro grace period:
	\begin{itemize}
		\item ERA = 20
		\item ESL = 45
		\item LEV = 20
		\item SWD = 20
	\end{itemize}
\end{itemize}

Como era de esperar, el conjunto de datos ESL, al ser bastante más pequeño que los demás, necesita un aumento del parámetro grace period.

Para el segundo algoritmo, el que trata los índices de monotonicidad de los nodos para decidir si hacer una expansión de este o no, posee además un parámetro de tolerancia de no-monotonicidad para evitar intentar conseguir árboles muy monótonos a costa de la pérdida de precisión. El parámetro es un simple factor del NMI calculado en cada nodo con respecto a las demás ramas. Los ajustes de este parámetro para los experimentos han sido calculados de forma empírica hasta obtener unos resultados óptimos. Estos son:
\begin{itemize}
	\item ERA = 0.5
	\item ESL = 0.45
	\item LEV = 1
	\item SWD = 0.45
\end{itemize}

\begin{table}[H]
	\begin{tabular}{|c|l|l|l|l|}
		\hline
		HF & ERA    & ESL    & LEV &  SWD \\ \hline
		MAE & 1.673 & 0.580 & 0.612                      & 0.625                     \\ \hline
		NMI & 0.4060 & 0.3856 & 0.3473                     & 0.3510                     \\ \hline
	\end{tabular}
\caption{Resultados de accuracy y monotonicidad para los 4 data sets descritos mediante el uso de Hoeffding Tree algorithm.}
\end{table}

\begin{table}[H]
	\begin{tabular}{|c|l|l|l|l|}
		\hline
		HF + Poda & ERA    & ESL    & LEV &  SWD \\ \hline
		MAE & 1.88 & 0.576 & 0.636                      & 0.66                     \\ \hline
		NMI & 0.3892 & 0.3849 & 0.3382                     & 0.342                     \\ \hline
	\end{tabular}
	\caption{Resultados de accuracy y monotonicidad para los 4 data sets descritos mediante el uso de Hoeffding Tree algorithm junto con poda.}
\end{table}

\begin{table}[H]
	\begin{tabular}{|c|l|l|l|l|}
		\hline
		HF + Decisión & ERA    & ESL    & LEV &  SWD \\ \hline
		MAE & 1.65 & 0.642 & 0.562                      & 0.62                     \\ \hline
		NMI & 0.3957 & 0.3791 & 0.3369                     & 0.3458                     \\ \hline
	\end{tabular}
	\caption{Resultados de accuracy y monotonicidad para los 4 data sets descritos mediante el uso de Hoeffding Tree algorithm junto con el algoritmo de toma de decisión a la hora de expandir.}
\end{table}

\begin{table}[H]
	\begin{tabular}{|c|l|l|l|l|}
		\hline
		HF + Poda + Decisión & ERA    & ESL    & LEV &  SWD \\ \hline
		MAE & 1.67 & 0.64 & 0.664                      & 0.629                     \\ \hline
		NMI & 0.3815 & 0.3790 & 0.3451                     & 0.3447                     \\ \hline
	\end{tabular}
	\caption{Resultados de accuracy y monotonicidad para los 4 data sets descritos mediante el uso de Hoeffding Tree algorithm junto con ambos algoritmos creados.}
\end{table}
\newpage

\section{Análisis}

A la vista de los resultados podemos observar que, aunque no en gran medida, la adición de restricciones monotónicas a los algoritmos de flujos de datos con árboles de decisión resulta ser exitosa, ya que el índice de no-monotonicidad desciende al aplicar cualquiera de los algoritmos creados, ya sea el de poda, el de toma de decisión a la hora de expandir los nodos o ambos al mismo tiempo.\\

Hemos de tener en cuenta también que los conjuntos de datos que estamos tratando en los experimentos son muy pequeños, el entorno de flujos de datos real ofrece cantidades masivas de datos que permiten a los algoritmos un aprendizaje más fiel del problema, quizá este sea el motivo de que el índice de monotonicidad descienda tan poco entre el algoritmo sin las restricciones y los que sí las tienen. Al no tener tantos datos hemos debido de modificar los parámetros de Hoeffding Tree para poder crear árboles lo suficientemente grandes que nos sirvan para poder probar nuestros algoritmos.\\

Por contra, podemos observar cómo en algunas ocasiones, un descenso de la monotonicidad viene acarreado de sanciones en la precisión del algoritmo, por lo que el índice MAE puede verse ligeramente mayor a la hora de aplicar estas restricciones monotónicas. Como dijimos capítulos atrás, el objetivo del presente documento era la disminución de la monotonicidad de los resultados predichos por nuestros algoritmos. Es probable que el algoritmo base, sin las restricciones de monotonía, alcance una precisión más alta pero que la interpretabilidad de los resultados predichos sea inferior a la de los resultados obtenidos por los algoritmos que sí aplican dichas restricciones.\\

En definitiva, teniendo en cuenta que el factor que hace que los resultados no sean tan significativos es el volumen de los conjuntos de datos tratado, podemos concluir que los resultados han sido exitosos ya que, aunque hemos obtenido mayor error en la predicción, la interpretabilidad de los resultados es mayor debido a la bajada de la no-monotonicidad en las predicciones.

\newpage











